#!/usr/bin/env python3
"""
Sociology Journal Fetcher â€” CrossRef API Edition
- å›½é™…æœŸåˆŠï¼šCrossRef APIï¼ˆæŒ‰ ISSN + æ—¥æœŸæŸ¥è¯¢ï¼Œæ— éœ€ RSS URLï¼‰
- è¿‡æ»¤ä¹¦è¯„ â†’ Gemini/Groq è¯„åˆ† â†’ å†™å…¥ Google Sheets
"""

import subprocess, json, os, re, functools
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.request import urlopen, Request

# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SHEET_ID    = "1MCcEqV2OGkxFofWSRI6BW2OFYG35cNDHC2olbm43NWc"
SHEET_RANGE = "è®ºæ–‡"
MAILTO      = "wangsenhu@gmail.com"   # CrossRef polite pool
GEMINI_KEYS = [k for k in [
    os.environ.get("GEMINI_API_KEY", ""),
    os.environ.get("GEMINI_API_KEY_2", ""),
    os.environ.get("GEMINI_API_KEY_3", ""),
] if k]
GROQ_API_KEY       = os.environ.get("GROQ_API_KEY", "")
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")
SGT = timezone(timedelta(hours=8))  # æ–°åŠ å¡æ—¶é—´ (SGT)
TARGET_DATE = (datetime.now(SGT) - timedelta(days=1)).strftime("%Y-%m-%d")

# â”€â”€ Gemini åŠ¨æ€æ¨¡å‹é€‰æ‹© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GEMINI_PREFERRED = [
    "gemini-2.5-flash",       # é¦–é€‰ï¼šæœ€æ–°æœ€ä¼˜ flash
    "gemini-2.0-flash",       # å¤‡é€‰ï¼šä¸Šä¸€ä»£ï¼Œæç¨³å®š
    "gemini-2.0-flash-lite",  # å†å¤‡ï¼šæ›´ä¾¿å®œ
    "gemini-1.5-flash",       # å…œåº•ï¼šè€ä½†æå¯é 
    "gemini-1.5-flash-8b",    # æœ€ç»ˆå…œåº•ï¼šæœ€ä¾¿å®œ
]
_EXCLUDE_KEYWORDS = ("pro", "preview", "exp", "thinking")

def _model_version_key(name):
    m = re.search(r'gemini-(\d+)[.\-](\d+)', name)
    return (int(m.group(1)), int(m.group(2))) if m else (0, 0)

@functools.lru_cache(maxsize=8)
def _list_gemini_models(api_key):
    """åˆ—å‡ºæŒ‡å®š API key å¯ç”¨çš„ Gemini æ¨¡å‹ï¼ˆçº¯ RESTï¼Œä¸ä¾èµ– SDKï¼Œç»“æœç¼“å­˜ï¼‰"""
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}&pageSize=200"
        with urlopen(url, timeout=10) as r:
            data = json.loads(r.read())
        return frozenset(
            m["name"].removeprefix("models/")
            for m in data.get("models", [])
            if "generateContent" in m.get("supportedGenerationMethods", [])
        )
    except Exception as e:
        print(f"   âš ï¸ æ— æ³•åˆ—å‡º Gemini æ¨¡å‹: {e}")
        return frozenset()

def get_best_gemini_model(api_key):
    """æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³å¯ç”¨ flash æ¨¡å‹ï¼Œæ’é™¤ pro/preview/exp/thinking"""
    available = _list_gemini_models(api_key)
    if not available:
        return "gemini-2.0-flash"  # åˆ—è¡¨å¤±è´¥æ—¶çš„é»˜è®¤å€¼
    for model in GEMINI_PREFERRED:
        if model in available:
            return model
    # æ‰€æœ‰ä¼˜å…ˆæ¨¡å‹å‡ä¸å¯ç”¨ï¼šè‡ªåŠ¨å¯»æ‰¾ç‰ˆæœ¬æœ€é«˜çš„ flash æ¨¡å‹
    candidates = [
        m for m in available
        if "flash" in m and not any(kw in m for kw in _EXCLUDE_KEYWORDS)
    ]
    if candidates:
        chosen = max(candidates, key=_model_version_key)
        print(f"   ğŸ“Œ è‡ªåŠ¨é™çº§è‡³: {chosen}")
        return chosen
    return "gemini-1.5-flash"

# â”€â”€ å›½é™…æœŸåˆŠï¼ˆCrossRefï¼ŒæŒ‰ ISSNï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JOURNALS = [
    # ç»¼åˆç¤¾ä¼šå­¦
    ("American Sociological Review",      "ç»¼åˆç¤¾ä¼šå­¦",    "0003-1224"),
    ("American Journal of Sociology",     "ç»¼åˆç¤¾ä¼šå­¦",    "0002-9602"),
    ("Annual Review of Sociology",        "ç»¼åˆç¤¾ä¼šå­¦",    "0360-0572"),
    ("Social Forces",                     "ç»¼åˆç¤¾ä¼šå­¦",    "0037-7732"),
    ("Sociological Methods & Research",   "ç»¼åˆç¤¾ä¼šå­¦",    "0049-1241"),
    ("European Sociological Review",      "ç»¼åˆç¤¾ä¼šå­¦",    "0266-7215"),
    ("British Journal of Sociology",      "ç»¼åˆç¤¾ä¼šå­¦",    "0007-1315"),
    ("Sociology (BSA)",                   "ç»¼åˆç¤¾ä¼šå­¦",    "0038-0385"),
    ("Work, Employment and Society",      "ç»¼åˆç¤¾ä¼šå­¦",    "0950-0170"),
    ("Chinese Sociological Review",       "ç»¼åˆç¤¾ä¼šå­¦",    "2162-0555"),
    # ç§»æ°‘ä¸æ—è£”
    ("International Migration Review",           "ç§»æ°‘ä¸æ—è£”", "0197-9183"),
    ("Journal of Ethnic and Migration Studies",  "ç§»æ°‘ä¸æ—è£”", "1369-183X"),
    ("International Migration",                  "ç§»æ°‘ä¸æ—è£”", "0020-7985"),
    # è®¡ç®—ç¤¾ä¼šç§‘å­¦
    ("Journal of Computational Social Science", "è®¡ç®—ç¤¾ä¼šç§‘å­¦", "2432-2717"),
    ("Social Science Computer Review",          "è®¡ç®—ç¤¾ä¼šç§‘å­¦", "0894-4393"),
    ("Nature Human Behaviour",                  "è®¡ç®—ç¤¾ä¼šç§‘å­¦", "2397-3374"),
    # ç¤¾ä¼šç½‘ç»œ
    ("Social Networks",  "ç¤¾ä¼šç½‘ç»œ", "0378-8733"),
    ("Network Science",  "ç¤¾ä¼šç½‘ç»œ", "2050-1242"),
    # ç¤¾ä¼šåˆ†å±‚ä¸æµåŠ¨
    ("Research in Social Stratification and Mobility", "ç¤¾ä¼šåˆ†å±‚ä¸æµåŠ¨", "0276-5624"),
    ("Social Science Research",                         "ç¤¾ä¼šåˆ†å±‚ä¸æµåŠ¨", "0049-089X"),
    # åŒ»å­¦ç¤¾ä¼šå­¦
    ("Social Science & Medicine",           "åŒ»å­¦ç¤¾ä¼šå­¦", "0277-9536"),
    ("Journal of Health and Social Behavior","åŒ»å­¦ç¤¾ä¼šå­¦", "0022-1465"),
    ("Sociology of Health & Illness",       "åŒ»å­¦ç¤¾ä¼šå­¦", "0141-9889"),
    # è€å¹´å­¦
    ("Journals of Gerontology Series B", "è€å¹´å­¦", "1079-5014"),
    ("The Gerontologist",                "è€å¹´å­¦", "0016-9013"),
    ("Journal of Aging and Health",      "è€å¹´å­¦", "0898-2643"),
    # å©šå§»ä¸å®¶åº­
    ("Journal of Marriage and Family", "å©šå§»ä¸å®¶åº­", "0022-2445"),
    ("Journal of Family Issues",       "å©šå§»ä¸å®¶åº­", "0192-513X"),
    # äººå£å­¦
    ("Demography",                      "äººå£å­¦", "0070-3370"),
    ("Population and Development Review","äººå£å­¦", "0098-7921"),
    ("Population Studies",              "äººå£å­¦", "0032-4728"),
    ("European Journal of Population",  "äººå£å­¦", "0168-6577"),
    ("Demographic Research",            "äººå£å­¦", "1435-9871"),
]


# â”€â”€ ä¹¦è¯„è¿‡æ»¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BOOK_REVIEW_KEYWORDS = [
    "book review", "review of ", "reviews of ",
    "book notice", "book symposium", "review essay", "book forum",
]

def is_book_review(title):
    t = title.lower()
    if any(kw in t for kw in BOOK_REVIEW_KEYWORDS):
        return True
    if re.search(r'\bISBN\b', title, re.IGNORECASE):
        return True
    if re.search(r'\bpp\.', title) and re.search(r'[Â£$â‚¬]\d', title):
        return True
    if re.search(r'\. By [A-Z].+?\.\s+\w+:', title):
        return True
    return False

# â”€â”€ CrossRef æŠ“å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_crossref(journal_name, field, issn):
    import time
    url = (
        f"https://api.crossref.org/works"
        f"?filter=issn:{issn},from-pub-date:{TARGET_DATE},until-pub-date:{TARGET_DATE}"
        f"&rows=50&select=title,author,DOI,URL,published,published-online,type"
        f"&mailto={MAILTO}"
    )
    req = Request(url, headers={"User-Agent": f"SociologyBot/1.0 (mailto:{MAILTO})"})
    data = None
    for attempt in range(4):
        try:
            with urlopen(req, timeout=30) as resp:
                data = json.loads(resp.read())
            break
        except Exception as e:
            if "429" in str(e) and attempt < 3:
                wait = (attempt + 1) * 15
                print(f"   â³ {journal_name}: é™é€Ÿï¼Œ{wait}ç§’åé‡è¯•...")
                time.sleep(wait)
            else:
                print(f"   âš ï¸  {journal_name}: å¤±è´¥ ({e})")
                return []
    if data is None:
        return []
    try:
        items = data.get("message", {}).get("items", [])
        articles = []
        for item in items:
            if item.get("type") != "journal-article":
                continue

            title_list = item.get("title", [])
            title = re.sub(r'<[^>]+>', '', title_list[0]).strip() if title_list else ""
            if not title or is_book_review(title):
                continue

            # æ—¥æœŸï¼šä¼˜å…ˆ published-online
            pub = item.get("published-online") or item.get("published") or {}
            parts = pub.get("date-parts", [[]])[0]
            if len(parts) >= 3:
                article_date = f"{parts[0]:04d}-{parts[1]:02d}-{parts[2]:02d}"
            else:
                continue  # æ—¥æœŸä¸å®Œæ•´è·³è¿‡

            if article_date != TARGET_DATE:
                continue

            # ä½œè€…
            authors = []
            for a in item.get("author", []):
                name = f"{a.get('given','')} {a.get('family','')}".strip()
                if name:
                    authors.append(name)

            doi  = item.get("DOI", "")
            link = item.get("URL") or (f"https://doi.org/{doi}" if doi else "")

            articles.append({
                "journal": journal_name, "field": field,
                "title":   title,
                "authors": ", ".join(authors) or "N/A",
                "date":    article_date,
                "link":    link,
            })

        print(f"   âœ… {journal_name}: {len(articles)} ç¯‡")
        return articles
    except Exception as e:
        print(f"   âš ï¸  {journal_name}: å¤±è´¥ ({e})")
        return []


# â”€â”€ è¯„åˆ† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def score_articles(articles):
    if not articles:
        return articles
    import time

    titles_list = "\n".join([
        f"{i+1}. [{a['journal']}] {a['title']}" for i, a in enumerate(articles)
    ])
    prompt = f"""ä½ æ˜¯ç¤¾ä¼šå­¦é¢†åŸŸçš„ä¸“å®¶æ•™æˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å­¦æœ¯è®ºæ–‡çš„é¢˜ç›®ï¼Œé€ä¸€ç”¨ä¸€å¥ä¸­æ–‡ç®€ä»‹è¯´æ˜è¿™ç¯‡è®ºæ–‡å¤§æ¦‚åœ¨ç ”ç©¶ä»€ä¹ˆã€‚

è¦æ±‚ï¼š
- åªæ ¹æ®é¢˜ç›®æ¨æ–­ï¼Œä¸è¦ç¼–é€ å†…å®¹
- æ¯æ¡ç®€ä»‹æ§åˆ¶åœ¨30å­—ä»¥å†…
- è¯­è¨€ç®€æ´ï¼Œç›´æ¥è¯´æ˜ç ”ç©¶ä¸»é¢˜

è®ºæ–‡åˆ—è¡¨ï¼š
{titles_list}

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
[
  {{"index": 1, "score": "ä¸€å¥è¯ä¸­æ–‡ç®€ä»‹"}},
  {{"index": 2, "score": "ä¸€å¥è¯ä¸­æ–‡ç®€ä»‹"}}
]"""

    def parse_scores(content):
        content = content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[-1].rsplit("```", 1)[0]
        start, end = content.find("["), content.rfind("]") + 1
        if start == -1 or end == 0:
            raise ValueError(f"No JSON array: {content[:80]!r}")
        return json.loads(content[start:end])

    def apply_scores(scores):
        score_map = {s["index"]: s["score"] for s in scores}
        for i, a in enumerate(articles):
            a["score"] = score_map.get(i + 1, "æš‚æ— ç®€ä»‹")

    # 1. Geminiï¼ˆåŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼‰
    def call_gemini(api_key):
        model = get_best_gemini_model(api_key)
        print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
        payload = json.dumps({
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"maxOutputTokens": 2000},
        }).encode()
        req = Request(
            f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}",
            data=payload, headers={"Content-Type": "application/json"},
        )
        with urlopen(req, timeout=60) as resp:
            result = json.loads(resp.read())
        parts = result["candidates"][0]["content"]["parts"]
        text = next((p["text"] for p in reversed(parts) if "text" in p), "").strip()
        return parse_scores(text)

    for key_idx, api_key in enumerate(GEMINI_KEYS):
        label = f"Gemini key{key_idx+1}"
        for attempt in range(3):
            try:
                apply_scores(call_gemini(api_key))
                print(f"   âœ… è¯„åˆ†å®Œæˆï¼ˆ{label}ï¼‰")
                return articles
            except Exception as e:
                if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                    if attempt < 2:
                        time.sleep((attempt + 1) * 10)
                        print(f"   â³ {label} é™é€Ÿï¼Œé‡è¯•ä¸­...")
                    else:
                        print(f"   â³ {label} æŒç»­é™é€Ÿï¼Œæ¢ä¸‹ä¸€ä¸ª key")
                else:
                    print(f"   âš ï¸  {label}: {e}ï¼Œæ¢ä¸‹ä¸€ä¸ª key")
                    break

    # 2. Groq
    if GROQ_API_KEY:
        try:
            payload = json.dumps({
                "model": "llama-3.3-70b-versatile",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
            }).encode()
            req = Request("https://api.groq.com/openai/v1/chat/completions", data=payload,
                headers={"Authorization": f"Bearer {GROQ_API_KEY}",
                         "Content-Type": "application/json", "User-Agent": "curl/7.88.1"})
            with urlopen(req, timeout=30) as resp:
                result = json.loads(resp.read())
            apply_scores(parse_scores(result["choices"][0]["message"]["content"].strip()))
            print("   âœ… è¯„åˆ†å®Œæˆï¼ˆGroqï¼‰")
            return articles
        except Exception as e:
            print(f"   âš ï¸  Groq: {e}")

    # 3. OpenRouter
    if OPENROUTER_API_KEY:
        for attempt in range(3):
            try:
                payload = json.dumps({
                    "model": "meta-llama/llama-3.3-70b-instruct:free",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1000,
                }).encode()
                req = Request("https://openrouter.ai/api/v1/chat/completions", data=payload,
                    headers={"Authorization": f"Bearer {OPENROUTER_API_KEY}",
                             "Content-Type": "application/json", "HTTP-Referer": "https://openclaw.ai"})
                with urlopen(req, timeout=30) as resp:
                    result = json.loads(resp.read())
                apply_scores(parse_scores(result["choices"][0]["message"]["content"].strip()))
                print("   âœ… è¯„åˆ†å®Œæˆï¼ˆOpenRouterï¼‰")
                return articles
            except Exception as e:
                if "429" in str(e):
                    time.sleep((attempt + 1) * 15)
                else:
                    print(f"   âš ï¸  OpenRouter: {e}"); break

    print("   âš ï¸  æ‰€æœ‰è¯„åˆ†æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†")
    for a in articles:
        a["score"] = "æš‚æ— ç®€ä»‹"
    return articles

# â”€â”€ å†™å…¥ Google Sheets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def write_to_sheets(articles):
    if not articles:
        print("æ²¡æœ‰æ–°æ–‡ç« ã€‚"); return

    from collections import defaultdict
    dates_order, by_date = [], defaultdict(list)
    for a in articles:
        if a["date"] not in by_date:
            dates_order.append(a["date"])
        by_date[a["date"]].append(a)

    rows = []
    for i, date in enumerate(sorted(dates_order)):
        day_articles = sorted(by_date[date], key=lambda x: x["field"])
        for a in day_articles:
            rows.append(["'" + a["date"], a["field"], a["journal"],
                         a["authors"], a["title"], a["score"], a["link"]])
        if i < len(dates_order) - 1:
            rows.append(["", "", "", "", "", "", ""])

    # ç¯å¢ƒæ£€æµ‹ï¼šå¦‚æœæœ‰ GOOGLE_SERVICE_ACCOUNTï¼Œè¯´æ˜åœ¨ GitHub/äº‘ç«¯è¿è¡Œ
    sa_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT", "")
    try:
        import gspread, base64
        from google.oauth2.service_account import Credentials

        if sa_json:
            # æœ¬åœ°/GitHub Actionsï¼šä½¿ç”¨ JSON keyï¼ˆBase64 æˆ–åŸå§‹ JSONï¼‰
            try:
                sa_info = json.loads(base64.b64decode(sa_json))
            except:
                sa_info = json.loads(sa_json)
            creds = Credentials.from_service_account_info(
                sa_info,
                scopes=["https://www.googleapis.com/auth/spreadsheets"]
            )
        else:
            # GCP Cloud Runï¼šä½¿ç”¨ Application Default Credentials
            import google.auth
            creds, _ = google.auth.default(
                scopes=["https://www.googleapis.com/auth/spreadsheets"])

        gc = gspread.authorize(creds)
        ws = gc.open_by_key(SHEET_ID).worksheet(SHEET_RANGE)
        # æ–°æ•°æ®ç½®é¡¶ï¼šç©ºè¡Œè¿½åŠ åœ¨æœ¬æ‰¹æ•°æ®åé¢ï¼Œè§†è§‰ä¸ŠåŒºåˆ†æ¯æ¬¡æŠ“å–æ‰¹æ¬¡
        separator = [["" ] * len(rows[0])]
        ws.insert_rows(rows + separator, row=2, value_input_option="USER_ENTERED")
        print(f"âœ… æˆåŠŸå†™å…¥ {len(articles)} ç¯‡æ–‡ç« åˆ° Google Sheetsï¼ˆå·²ç½®é¡¶ï¼‰")
    except Exception as e:
        print(f"âŒ gspread å†™å…¥å¤±è´¥: {e}")

# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print(f"ğŸ” æŠ“å–æ—¥æœŸ: {TARGET_DATE}")
    print(f"ğŸ“š {len(JOURNALS)} ä¸ªå›½é™…æœŸåˆŠï¼ˆCrossRefï¼‰\n")

    all_articles = []

    with ThreadPoolExecutor(max_workers=3) as ex:
        futures = {ex.submit(fetch_crossref, n, f, i): n for n, f, i in JOURNALS}
        for future in as_completed(futures):
            all_articles.extend(future.result())

    print(f"\nğŸ“ å…±æ‰¾åˆ° {len(all_articles)} ç¯‡æ˜¨å¤©çš„æ–‡ç« ")
    if not all_articles:
        print("æ²¡æœ‰æ–°æ–‡ç« ï¼Œé€€å‡ºã€‚"); return

    print("ğŸ¤– æ­£åœ¨è¯„åˆ†ï¼ˆå•æ¬¡ LLM è°ƒç”¨ï¼‰...")
    all_articles = score_articles(all_articles)

    print("ğŸ“Š å†™å…¥ Google Sheets...")
    write_to_sheets(all_articles)

if __name__ == "__main__":
    main()
